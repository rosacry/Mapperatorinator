defaults:
  - train
  - _self_
  - model: whisper_base

compile: true          # PyTorch 2.0 optimization
precision: 'bf16'         # Enable mixed precision (no/fp16/bf16/fp8)

data:                  # Data settings
  train_dataset_path: "/workspace/datasets/ORS16291"
  test_dataset_path: "/workspace/datasets/ORS16291"
  add_diff_token: true
  add_mapper_token: true
  add_cs_token: true
  add_descriptors: true
  timing_random_offset: 2
  src_seq_len: 1024
  tgt_seq_len: 1536
  rhythm_weight: 3.0    # Weight of rhythm tokens in the loss calculation
  context_types:       # List of context types to include in the dataset
    - "in": ['${context_type:none}']
      "out": ['${context_type:timing}']
    - "in": ['${context_type:timing}']
      "out": ['${context_type:map}']
    - "in": ['${context_type:timing}', '${context_type:no_hs}']
      "out": ['${context_type:map}']
    - "in": ['${context_type:timing}', '${context_type:gd}']
      "out": ['${context_type:map}']
  context_weights: [2, 2, 1, 1]    # List of weights for each context type. Determines how often each context type is sampled
  descriptors_path: "../../../datasets/beatmap_descriptors.csv"   # Path to file with all beatmap descriptors
  mappers_path: "../../../datasets/beatmap_users.json"       # Path to file with all beatmap mappers
  add_timing: false      # Interweave timing tokens with the beatmap tokens
  add_snapping: true    # Model hit object snapping
  add_timing_points: true  # Model beatmap timing with timing points
  add_hitsounds: true   # Model beatmap hitsounds
  add_pre_tokens: false
  per_track: true
  add_distances: true   # Model hit object distances
  add_positions: true
  position_precision: 32  # Precision of hit object coordinates
  position_split_axes: false  # Split hit object X and Y coordinates into separate tokens
  dt_augment_prob: 0.7   # Probability of augmenting the dataset with DT
  dt_augment_range: [1.25, 1.5]  # Range of DT augmentation
  types_first: true       # Put the type token at the start of the group before the timeshift token

dataloader:             # Dataloader settings
  num_workers: 8

optim:                  # Optimizer settings
  base_lr: 1e-2         # Should not be scaled with the number of devices present
  batch_size: 128
  grad_acc: 8