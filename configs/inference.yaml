model_path: ''          # Path to trained model
audio_path: ''          # Path to input audio
output_path: ''         # Path to output directory
beatmap_path: ''        # Path to .osu file to autofill metadata
other_beatmap_path: ''  # Path to .osu file of other beatmap in the mapset to use as reference
lookback: 0             # Fraction of audio sequence to fill with tokens from previous inference window
lookahead: 0            # Fraction of audio sequence to skip at the end of the audio window
gamemode: 0             # Gamemode of the beatmap
beatmap_id: -1          # Beatmap ID to use as style
difficulty: -1          # Difficulty star rating to map
mapper_id: -1           # Mapper ID to use as style
year: -1                # Year to use as style
circle_size: -1         # Circle size to use for style
keycount: 4             # Number of keys to use for mania
hold_note_ratio: -1     # Ratio of how many hold notes to generate in mania
scroll_speed_ratio: -1  # Ratio of how many scroll speed changes to generate in mania and taiko
descriptors: []         # List of descriptors to use for style
negative_descriptors: []# List of descriptors to avoid when using classifier-free guidance
timing_leniency: 20     # Number of milliseconds of error to allow for timing generation
in_context: []          # Context types of other beatmap(s)
output_type: 'map'      # Output type (map, timing)
seed: 0                 # Random seed
cfg_scale: 1.0              # Scale of classifier-free guidance
temperature: 1.0        # Sampling temperature
top_p: 0.95              # Top-p sampling threshold
timeshift_bias: 0.0        # Logit bias for sampling timeshift tokens

bpm: 120                # Beats per minute of input audio
offset: 0               # Start of beat, in miliseconds, from the beginning of input audio
slider_multiplier: 1.8  # Multiplier for slider velocity
title: ''               # Song title
artist: ''              # Song artist
creator: 'osuT5'        # Beatmap creator
version: 'osuT5'        # Beatmap version
background: ''          # File name of background image
preview_time: -1        # Time in milliseconds to start previewing the song

# Diffusion settings
generate_positions: false      # Use diffusion to generate object positions
diff_cfg_scale: 1.0              # Scale of classifier-free guidance
compile: false          # PyTorch 2.0 optimization
pad_sequence: false     # Pad sequence to max_seq_len
diff_ckpt: ''                  # Path to checkpoint for diffusion model
diff_refine_ckpt: ''           # Path to checkpoint for refining diffusion model
beatmap_idx: 'osu_diffusion/beatmap_idx.pickle'  # Path to beatmap index
refine_iters: 10                  # Number of refinement iterations
random_init: true           # Whether to initialize with random noise instead of positions generated by the previous model
timesteps: [1000]  # The number of timesteps we want to take from equally-sized portions of the original process
max_seq_len: 1024  # Maximum sequence length for diffusion
overlap_buffer: 128  # Buffer zone at start and end of sequence to avoid edge effects (should be less than half of max_seq_len)

hydra:
  job:
    chdir: False
  run:
    dir: ./logs/${now:%Y-%m-%d}/${now:%H-%M-%S}